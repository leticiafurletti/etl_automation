{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download dos dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name.basics.tsv.gz já existe. Pulando o download.\n",
      "title.akas.tsv.gz já existe. Pulando o download.\n",
      "title.basics.tsv.gz já existe. Pulando o download.\n",
      "title.crew.tsv.gz já existe. Pulando o download.\n",
      "title.episode.tsv.gz já existe. Pulando o download.\n",
      "title.principals.tsv.gz já existe. Pulando o download.\n",
      "title.ratings.tsv.gz já existe. Pulando o download.\n",
      "Download concluído.\n"
     ]
    }
   ],
   "source": [
    "# download dos arquivos\n",
    "\n",
    "# URL base para os datasets do IMDb\n",
    "base_url = \"https://datasets.imdbws.com/\"\n",
    "\n",
    "# Lista de nomes de arquivos que você deseja baixar\n",
    "arquivos = [\n",
    "    \"name.basics.tsv.gz\",\n",
    "    \"title.akas.tsv.gz\",\n",
    "    \"title.basics.tsv.gz\",\n",
    "    \"title.crew.tsv.gz\",\n",
    "    \"title.episode.tsv.gz\",\n",
    "    \"title.principals.tsv.gz\",\n",
    "    \"title.ratings.tsv.gz\"\n",
    "]\n",
    "\n",
    "# Diretório de destino\n",
    "destino_diretorio = \"data\"\n",
    "\n",
    "# Certifique-se de que o diretório de destino existe\n",
    "os.makedirs(destino_diretorio, exist_ok=True)\n",
    "\n",
    "# Loop para baixar cada arquivo\n",
    "for arquivo in arquivos:\n",
    "    url = base_url + arquivo\n",
    "    caminho_destino = os.path.join(destino_diretorio, arquivo)\n",
    "    # Verifica se o arquivo já existe para evitar o download repetido\n",
    "    if not os.path.exists(caminho_destino):\n",
    "        print(f\"Baixando {arquivo}...\")\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Verifica se a solicitação foi bem-sucedida (código de status 200)\n",
    "        if response.status_code == 200:\n",
    "            with open(caminho_destino, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"{arquivo} baixado com sucesso!\")\n",
    "        else:\n",
    "            print(f\"Falha ao baixar {arquivo}. Código de status: {response.status_code}\")\n",
    "    else:\n",
    "        print(f\"{arquivo} já existe. Pulando o download.\")\n",
    "\n",
    "print(\"Download concluído.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Transformação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo e tratando o arquivo name.basics.tsv.gz...\n",
      "Tratamento concluído para name.basics.tsv.gz. Arquivo tratado salvo em data\\tratados\\name.basics.tsv\n",
      "Lendo e tratando o arquivo title.akas.tsv.gz...\n",
      "Tratamento concluído para title.akas.tsv.gz. Arquivo tratado salvo em data\\tratados\\title.akas.tsv\n",
      "Lendo e tratando o arquivo title.basics.tsv.gz...\n",
      "Tratamento concluído para title.basics.tsv.gz. Arquivo tratado salvo em data\\tratados\\title.basics.tsv\n",
      "Lendo e tratando o arquivo title.crew.tsv.gz...\n",
      "Tratamento concluído para title.crew.tsv.gz. Arquivo tratado salvo em data\\tratados\\title.crew.tsv\n",
      "Lendo e tratando o arquivo title.episode.tsv.gz...\n",
      "Tratamento concluído para title.episode.tsv.gz. Arquivo tratado salvo em data\\tratados\\title.episode.tsv\n",
      "Lendo e tratando o arquivo title.principals.tsv.gz...\n",
      "Tratamento concluído para title.principals.tsv.gz. Arquivo tratado salvo em data\\tratados\\title.principals.tsv\n",
      "Lendo e tratando o arquivo title.ratings.tsv.gz...\n",
      "Tratamento concluído para title.ratings.tsv.gz. Arquivo tratado salvo em data\\tratados\\title.ratings.tsv\n",
      "Todos os arquivos foram tratados e salvos no diretório 'tratados'.\n"
     ]
    }
   ],
   "source": [
    "#TRANSFORMAÇÃO DOS DADOS\n",
    "\n",
    "# Diretórios\n",
    "diretorio_dados = \"data\"\n",
    "diretorio_tratados = os.path.join(diretorio_dados, \"tratados\") #colocar os datasets já tratados, salvo dentro da pasta data\n",
    "\n",
    "# Certifica-se de que o diretório \"tratados\" existe\n",
    "os.makedirs(diretorio_tratados, exist_ok=True)\n",
    "\n",
    "# Lista todos os arquivos no diretório \"data\"\n",
    "arquivos = os.listdir(diretorio_dados)\n",
    "\n",
    "# Loop para abrir, tratar e salvar cada arquivo\n",
    "for arquivo in arquivos:\n",
    "    caminho_arquivo = os.path.join(diretorio_dados, arquivo) \n",
    "\n",
    "    if os.path.isfile(caminho_arquivo) and arquivo.endswith(\".gz\"):\n",
    "        print(f\"Lendo e tratando o arquivo {arquivo}...\")\n",
    "        \n",
    "        # Lê o arquivo TSV usando o pandas\n",
    "        df = pd.read_csv(caminho_arquivo, sep='\\t', compression='gzip', low_memory=False) #coloca-se compression gzip pois meus arquivos estão comprimidos dessa fotma\n",
    "\n",
    "        # Trtamento de dados:  Substitui os caracteres \"\\n\" por nulo\n",
    "        df.replace({\"\\\\N\": None}, inplace=True)\n",
    "\n",
    "        # Salva o DataFrame no diretório \"tratados\" sem compressão gzip\n",
    "        caminho_destino = os.path.join(diretorio_tratados, arquivo[:-3])  # Remove a extensão .gz\n",
    "        df.to_csv(caminho_destino, sep='\\t', index=False)\n",
    "\n",
    "        print(f\"Tratamento concluído para {arquivo}. Arquivo tratado salvo em {caminho_destino}\")\n",
    "\n",
    "print(\"Todos os arquivos foram tratados e salvos no diretório 'tratados'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nconst</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>deathYear</th>\n",
       "      <th>primaryProfession</th>\n",
       "      <th>knownForTitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm0000001</td>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>soundtrack,actor,miscellaneous</td>\n",
       "      <td>tt0027125,tt0050419,tt0053137,tt0072308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0000002</td>\n",
       "      <td>Lauren Bacall</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>actress,soundtrack</td>\n",
       "      <td>tt0038355,tt0037382,tt0075213,tt0117057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0000003</td>\n",
       "      <td>Brigitte Bardot</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actress,soundtrack,music_department</td>\n",
       "      <td>tt0049189,tt0054452,tt0056404,tt0057345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0000004</td>\n",
       "      <td>John Belushi</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>actor,soundtrack,writer</td>\n",
       "      <td>tt0078723,tt0080455,tt0072562,tt0077975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm0000005</td>\n",
       "      <td>Ingmar Bergman</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>writer,director,actor</td>\n",
       "      <td>tt0083922,tt0069467,tt0050976,tt0050986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nconst      primaryName  birthYear  deathYear  \\\n",
       "0  nm0000001     Fred Astaire     1899.0     1987.0   \n",
       "1  nm0000002    Lauren Bacall     1924.0     2014.0   \n",
       "2  nm0000003  Brigitte Bardot     1934.0        NaN   \n",
       "3  nm0000004     John Belushi     1949.0     1982.0   \n",
       "4  nm0000005   Ingmar Bergman     1918.0     2007.0   \n",
       "\n",
       "                     primaryProfession  \\\n",
       "0       soundtrack,actor,miscellaneous   \n",
       "1                   actress,soundtrack   \n",
       "2  actress,soundtrack,music_department   \n",
       "3              actor,soundtrack,writer   \n",
       "4                writer,director,actor   \n",
       "\n",
       "                            knownForTitles  \n",
       "0  tt0027125,tt0050419,tt0053137,tt0072308  \n",
       "1  tt0038355,tt0037382,tt0075213,tt0117057  \n",
       "2  tt0049189,tt0054452,tt0056404,tt0057345  \n",
       "3  tt0078723,tt0080455,tt0072562,tt0077975  \n",
       "4  tt0083922,tt0069467,tt0050976,tt0050986  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validando dataframe\n",
    "df = pd.read_csv('./data/tratados/name.basics.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nconst                      0\n",
       "primaryName                 7\n",
       "birthYear            12701967\n",
       "deathYear            13083873\n",
       "primaryProfession     2686026\n",
       "knownForTitles        1579489\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Verifica a quantidade de dados nulos por coluna\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Salvando em banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo name.basics.tsv salvo como tabela name_basics no banco de dados.\n",
      "Arquivo title.akas.tsv salvo como tabela title_akas no banco de dados.\n",
      "Arquivo title.basics.tsv salvo como tabela title_basics no banco de dados.\n",
      "Arquivo title.crew.tsv salvo como tabela title_crew no banco de dados.\n",
      "Arquivo title.episode.tsv salvo como tabela title_episode no banco de dados.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 463. MiB for an array with shape (60735468,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m caminho_arquivo \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(diretorio_tratados, arquivo)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(caminho_arquivo) \u001b[38;5;129;01mand\u001b[39;00m arquivo\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Lê o arquivo TSV usando o pandas\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaminho_arquivo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Remove a extensão do nome do arquivo\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     nome_tabela \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(arquivo)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Leticia Furletti\\anaconda3\\envs\\Data_science\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Leticia Furletti\\anaconda3\\envs\\Data_science\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Leticia Furletti\\anaconda3\\envs\\Data_science\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m     (\n\u001b[0;32m   1745\u001b[0m         index,\n\u001b[0;32m   1746\u001b[0m         columns,\n\u001b[0;32m   1747\u001b[0m         col_dict,\n\u001b[1;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Leticia Furletti\\anaconda3\\envs\\Data_science\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:239\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "File \u001b[1;32mparsers.pyx:825\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:920\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:1065\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:1119\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:1221\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:1830\u001b[0m, in \u001b[0;36mpandas._libs.parsers._try_int64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 463. MiB for an array with shape (60735468,) and data type int64"
     ]
    }
   ],
   "source": [
    "# Salvando em banco de dados com o SQLite\n",
    "\n",
    "# Diretórios\n",
    "diretorio_tratados = os.path.join(\"data\", \"tratados\")\n",
    "banco_dados = \"imdb_data.db\"\n",
    "\n",
    "# Conecta ao banco de dados SQLite\n",
    "conexao = sqlite3.connect(banco_dados)\n",
    "\n",
    "# Lista todos os arquivos no diretório \"tratados\"\n",
    "arquivos = os.listdir(diretorio_tratados)\n",
    "\n",
    "# Loop para ler cada arquivo e salvar em uma tabela SQLite\n",
    "for arquivo in arquivos:\n",
    "    caminho_arquivo = os.path.join(diretorio_tratados, arquivo)\n",
    "\n",
    "    if os.path.isfile(caminho_arquivo) and arquivo.endswith(\".tsv\"):\n",
    "        # Lê o arquivo TSV usando o pandas\n",
    "        df = pd.read_csv(caminho_arquivo, sep='\\t', low_memory=False)\n",
    "\n",
    "        # Remove a extensão do nome do arquivo\n",
    "        nome_tabela = os.path.splitext(arquivo)[0]\n",
    "\n",
    "        # Substitui os caracteres especiais no nome da tabela\n",
    "        nome_tabela = nome_tabela.replace(\".\", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "        # Salva o DataFrame na tabela SQLite\n",
    "        df.to_sql(nome_tabela, conexao, index=False, if_exists='replace')\n",
    "\n",
    "        print(f\"Arquivo {arquivo} salvo como tabela {nome_tabela} no banco de dados.\")\n",
    "\n",
    "# Fecha a conexão com o banco de dados\n",
    "conexao.close()\n",
    "\n",
    "print(\"Todos os arquivos foram salvos no banco de dados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo title.principals.tsv salvo como tabela title_principals no banco de dados.\n",
      "Todos os arquivos foram salvos no banco de dados.\n"
     ]
    }
   ],
   "source": [
    "# Salvando em banco de dados com o SQLite (separei o arquivo maior, para conseguir acompanhar a ocupaçao de memoria do meu computador)\n",
    "\n",
    "# Diretórios\n",
    "diretorio_tratados = os.path.join(\"data\", \"tratados\")\n",
    "banco_dados = \"imdb_data.db\"\n",
    "\n",
    "# Conecta ao banco de dados SQLite\n",
    "conexao = sqlite3.connect(banco_dados)\n",
    "\n",
    "arquivos_especificos = [\"title.principals.tsv\"]\n",
    "\n",
    "# Loop para ler cada arquivo e salvar em uma tabela SQLite\n",
    "for arquivo in arquivos_especificos:\n",
    "    caminho_arquivo = os.path.join(diretorio_tratados, arquivo)\n",
    "\n",
    "    if os.path.isfile(caminho_arquivo) and arquivo.endswith(\".tsv\"):\n",
    "        # Lê o arquivo TSV usando o pandas\n",
    "        df = pd.read_csv(caminho_arquivo, sep='\\t', low_memory=True)\n",
    "\n",
    "        # Remove a extensão do nome do arquivo\n",
    "        nome_tabela = os.path.splitext(arquivo)[0]\n",
    "\n",
    "        # Substitui os caracteres especiais no nome da tabela\n",
    "        nome_tabela = nome_tabela.replace(\".\", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "        # Salva o DataFrame na tabela SQLite\n",
    "        df.to_sql(nome_tabela, conexao, index=False, if_exists='replace')\n",
    "\n",
    "        print(f\"Arquivo {arquivo} salvo como tabela {nome_tabela} no banco de dados.\")\n",
    "\n",
    "# Fecha a conexão com o banco de dados\n",
    "conexao.close()\n",
    "\n",
    "print(\"Todos os arquivos foram salvos no banco de dados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabelas no banco de dados:\n",
      "name_basics\n",
      "title_akas\n",
      "title_basics\n",
      "title_crew\n",
      "title_episode\n",
      "title_ratings\n",
      "title_principals\n"
     ]
    }
   ],
   "source": [
    "# Nome do banco de dados\n",
    "banco_dados = \"imdb_data.db\"\n",
    "\n",
    "# Conecta-se ao banco de dados SQLite\n",
    "conexao = sqlite3.connect(banco_dados)\n",
    "\n",
    "# Cria um cursor\n",
    "cursor = conexao.cursor()\n",
    "\n",
    "# Executa a consulta SQL para obter o nome das tabelas\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "# Recupera os resultados da consulta\n",
    "tabelas = cursor.fetchall()\n",
    "\n",
    "# Exibe o nome das tabelas\n",
    "print(\"Tabelas no banco de dados:\")\n",
    "for tabela in tabelas:\n",
    "    print(tabela[0])\n",
    "\n",
    "# Fecha o cursor e a conexão com o banco de dados\n",
    "cursor.close()\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conecta-se ao banco de dados SQLite\n",
    "conexao = sqlite3.connect(banco_dados)\n",
    "\n",
    "# Executa a consulta SQL para obter as 10 primeiras linhas da tabela name_basics\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM title_crew\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, conexao)\n",
    "\n",
    "# Fecha a conexão com o banco de dados\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>directors</th>\n",
       "      <th>writers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>nm0005690</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>nm0721526</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>nm0721526</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>nm0721526</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>nm0005690</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tt0000006</td>\n",
       "      <td>nm0005690</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tt0000007</td>\n",
       "      <td>nm0005690,nm0374658</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tt0000008</td>\n",
       "      <td>nm0005690</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tt0000009</td>\n",
       "      <td>nm0085156</td>\n",
       "      <td>nm0085156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tt0000010</td>\n",
       "      <td>nm0525910</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst            directors    writers\n",
       "0  tt0000001            nm0005690       None\n",
       "1  tt0000002            nm0721526       None\n",
       "2  tt0000003            nm0721526       None\n",
       "3  tt0000004            nm0721526       None\n",
       "4  tt0000005            nm0005690       None\n",
       "5  tt0000006            nm0005690       None\n",
       "6  tt0000007  nm0005690,nm0374658       None\n",
       "7  tt0000008            nm0005690       None\n",
       "8  tt0000009            nm0085156  nm0085156\n",
       "9  tt0000010            nm0525910       None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "analitico_titulos = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS analitico_titulos AS\n",
    "\n",
    "WITH \n",
    "participantes AS (\n",
    "    SELECT\n",
    "        tconst,\n",
    "        COUNT(DISTINCT nconst) as qtParticipantes\n",
    "    \n",
    "    FROM title_principals\n",
    "    \n",
    "    GROUP BY 1\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    tb.tconst,\n",
    "    tb.titleType,\n",
    "    tb.originalTitle,\n",
    "    tb.startYear,\n",
    "    tb.endYear,\n",
    "    tb.genres,\n",
    "    tr.averageRating,\n",
    "    tr.numVotes,\n",
    "    tp.qtParticipantes\n",
    "\n",
    "FROM title_basics tb \n",
    "\n",
    "LEFT JOIN title_ratings tr\n",
    "    ON tr.tconst = tb.tconst\n",
    "\n",
    "LEFT JOIN participantes tp\n",
    "    ON tp.tconst = tb.tconst\n",
    "\"\"\"\n",
    "\n",
    "analitico_participantes = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS analitico_participantes AS\n",
    "\n",
    "SELECT\n",
    "    tp.nconst,\n",
    "    tp.tconst,\n",
    "    tp.ordering,\n",
    "    tp.category,\n",
    "    tb.genres\n",
    "\n",
    "FROM title_principals tp\n",
    "\n",
    "LEFT JOIN title_basics tb\n",
    "    ON tb.tconst = tp.tconst\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabelas criadas com sucesso.\n",
      "Tabelas criadas com sucesso.\n"
     ]
    }
   ],
   "source": [
    "#lista de consultas\n",
    "queries = [analitico_titulos, analitico_participantes]\n",
    "\n",
    "for query in queries:\n",
    "\n",
    "    # Diretórios\n",
    "    banco_dados = \"imdb_data.db\"\n",
    "    \n",
    "    # Conecta ao banco de dados SQLite\n",
    "    conexao = sqlite3.connect(banco_dados)\n",
    "    \n",
    "    # Consulta SQL para contar o número de pessoas participantes por título\n",
    "    query = query\n",
    "    \n",
    "    # Executa a consulta SQL\n",
    "    conexao.execute(query)\n",
    "    \n",
    "    # Fecha a conexão com o banco de dados\n",
    "    conexao.close()\n",
    "    \n",
    "    print(\"Tabelas criadas com sucesso.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
